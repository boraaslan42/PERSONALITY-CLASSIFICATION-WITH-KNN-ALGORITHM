{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555af4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bora Aslan\n",
    "#2220356080\n",
    "import numpy as np # for arrays\n",
    "import pandas as pd # to read csv as dataframe\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6570c17d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"16P.csv\", encoding=\"iso8859\")\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data.drop([\"Response Id\"], axis=1, inplace=True)\n",
    "\n",
    "pNames = {\"ESTJ\": 0, \"ENTJ\": 1, \"ESFJ\": 2, \"ENFJ\": 3, \"ISTJ\": 4, \"ISFJ\": 5, \"INTJ\": 6, \"INFJ\": 7, \"ESTP\": 8, \"ESFP\": 9,\n",
    "          \"ENTP\": 10, \"ENFP\": 11, \"ISTP\": 12, \"ISFP\": 13, \"INTP\": 14, \"INFP\": 15}\n",
    "\n",
    "data['numericMBTI'] = data['Personality'].map(pNames)\n",
    "\n",
    "data.drop(columns=['Personality'], inplace=True)\n",
    "\n",
    "#normalizing data which is -3 to 3 by simple math\n",
    "#except numericMBTI column obviously!\n",
    "data.iloc[:,:-1] = ((data.iloc[:,:-1] +3) / (6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d66b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_distance(a, b):\n",
    "    distance = np.sqrt(np.sum((a - b) ** 2, axis=1))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236f54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.iloc[:int(len(data) * 0.1), :-1]\n",
    "y_train = data.iloc[:int(len(data) * 0.1), -1:]\n",
    "\n",
    "last_row = X_train.iloc[-1:, :]\n",
    "last_rowy = y_train.iloc[-1:, :]\n",
    "\n",
    "X_train = pd.concat([X_train, last_row], axis=0, ignore_index=True)\n",
    "y_train = pd.concat([y_train, last_rowy], axis=0, ignore_index=True)\n",
    "\n",
    "X_train_np = X_train.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "\n",
    "X_train_list = np.array_split(X_train_np, 5)\n",
    "y_train_list = np.array_split(y_train_np, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e85363",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Parameter is 1, results:\n",
      "Recall is 96.7094%\n",
      "Precision is 99.7066%\n",
      "Accuracy is 99.7771%\n",
      "---------------------------\n",
      "K Parameter is 3, results:\n",
      "Recall is 98.1735%\n",
      "Precision is 99.8981%\n",
      "Accuracy is 99.8802%\n",
      "---------------------------\n",
      "K Parameter is 5, results:\n",
      "Recall is 98.4044%\n",
      "Precision is 99.8786%\n",
      "Accuracy is 99.8937%\n",
      "---------------------------\n",
      "K Parameter is 7, results:\n",
      "Recall is 98.5740%\n",
      "Precision is 99.9314%\n",
      "Accuracy is 99.9073%\n",
      "---------------------------\n",
      "K Parameter is 9, results:\n",
      "Recall is 98.6281%\n",
      "Precision is 99.9315%\n",
      "Accuracy is 99.9104%\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "for K in [1, 3, 5, 7, 9]:# to execute the code for each K value\n",
    "    \n",
    "    matrix = [[0 for i in range(16)] for i in range(16)]\n",
    "    #confusion matrix created to store results\n",
    "    \n",
    "    for i in range(5):\n",
    "        #for cross validation 4 piece of train lists gets together again as train piece and \n",
    "        #remaining piece is test piece\n",
    "        fourpiece = X_train_list[:i] + X_train_list[i + 1:]\n",
    "        test_np = np.concatenate(fourpiece, axis=0)\n",
    "\n",
    "        f0urpiece = y_train_list[:i] + y_train_list[i + 1:]\n",
    "        y_train_np = np.concatenate(f0urpiece, axis=0)\n",
    "        \n",
    "        \n",
    "        for j in range(len(X_train_list[i])):\n",
    "            testline = X_train_list[i][j]\n",
    "            testliney = y_train_list[i][j]\n",
    "            distance = cal_distance(testline, test_np)\n",
    "            k_neighbors = y_train_np[np.argsort(distance)[:K]]\n",
    "            arr_1d = np.ravel(k_neighbors)\n",
    "            \n",
    "            counts = np.bincount(arr_1d)\n",
    "            prediction = np.argwhere(counts == counts.max()).flatten()\n",
    "\n",
    "            if len(prediction) != 1:\n",
    "                #print(prediction) DELETE THE # TO SEE KNN TIES\n",
    "                prediction = prediction[0]\n",
    "            matrix[testliney.item()][prediction.item()] += 1\n",
    "            \n",
    "    #calculating TP,TN,FP,FN to derive precision,recall and accuracy\n",
    "    total = 0\n",
    "    for i in range(16):#runs for every class once\n",
    "        \n",
    "        for l in range(16):#calculates the amount of entries to matrix to find the size\n",
    "            \n",
    "            total += matrix[i][l]\n",
    "    #general variables set to 0\n",
    "    recallT = 0\n",
    "    precisionT = 0\n",
    "    accuracynominatorT = 0\n",
    "    \n",
    "    for i in range(16):# this i is used as row index for FN, column index for FP\n",
    "        TP = matrix[i][i]\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "        for j in range(16):# this j is used as column index for FN, row index for FP\n",
    "            if i == j:\n",
    "                continue\n",
    "            FN += matrix[i][j]\n",
    "            FP = matrix[j][i]\n",
    "\n",
    "        TN = total - FN - FP - TP\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "\n",
    "        precisionT += precision\n",
    "\n",
    "        recall = TP / (TP + FN)\n",
    "\n",
    "        recallT += recall\n",
    "\n",
    "        accuracynominatorT += TP + TN\n",
    "\n",
    "    print(\"K Parameter is {}, results:\".format(K))\n",
    "    print(\"Recall is {:.4f}%\".format(100 * recallT / 16))\n",
    "    print(\"Precision is {:.4f}%\".format(100 * precisionT / 16))\n",
    "    print(\"Accuracy is {:.4f}%\".format(100 * accuracynominatorT / (total * 16)))\n",
    "    print(\"---------------------------\")\n",
    "#Error Analysis for Classification\n",
    "#During the implementation of my KNN classifier, I encountered an issue where there were instances where the closest k points\n",
    "#belonged to multiple classes, resulting in ties. This is due to the nature of the KNN algorithm, which relies on the distance\n",
    "#between points to determine the class of a given instance and could be revialed if the input questions are just\n",
    "#aligned in a way. You can see the ties that happens by going up lines and removing the # i put on line tht catchs ties and \n",
    "#picks the closest class as predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394f18c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
